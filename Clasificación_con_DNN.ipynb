{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ynhvlq98xwv",
        "outputId": "7690b9ee-49aa-4cf9-803f-d41cb1eb786a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJxVYZWxg2mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0492412-bfd2-4f12-cd5a-9e32252eb00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'alzheimers-disease-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/alzheimers-disease-dataset\n"
          ]
        }
      ],
      "source": [
        "#Importar los datos para el modelo\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rabieelkharoua/alzheimers-disease-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#Ruta de los datos\n",
        "db_path = os.path.join(\"/kaggle/input/alzheimers-disease-dataset/alzheimers_disease_data.csv\")"
      ],
      "metadata": {
        "id": "6RRmF3zi9N1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testeo de datos, registros e información del CSV\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(db_path)\n",
        "print(data.head())\n",
        "print(\"------------------------------------------------------------------\")\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thKf5N49B5Ql",
        "outputId": "3fb42002-85ef-4251-c872-e8bc973cf105",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PatientID  Age  Gender  Ethnicity  EducationLevel        BMI  Smoking  \\\n",
            "0       4751   73       0          0               2  22.927749        0   \n",
            "1       4752   89       0          0               0  26.827681        0   \n",
            "2       4753   73       0          3               1  17.795882        0   \n",
            "3       4754   74       1          0               1  33.800817        1   \n",
            "4       4755   89       0          0               0  20.716974        0   \n",
            "\n",
            "   AlcoholConsumption  PhysicalActivity  DietQuality  ...  MemoryComplaints  \\\n",
            "0           13.297218          6.327112     1.347214  ...                 0   \n",
            "1            4.542524          7.619885     0.518767  ...                 0   \n",
            "2           19.555085          7.844988     1.826335  ...                 0   \n",
            "3           12.209266          8.428001     7.435604  ...                 0   \n",
            "4           18.454356          6.310461     0.795498  ...                 0   \n",
            "\n",
            "   BehavioralProblems       ADL  Confusion  Disorientation  \\\n",
            "0                   0  1.725883          0               0   \n",
            "1                   0  2.592424          0               0   \n",
            "2                   0  7.119548          0               1   \n",
            "3                   1  6.481226          0               0   \n",
            "4                   0  0.014691          0               0   \n",
            "\n",
            "   PersonalityChanges  DifficultyCompletingTasks  Forgetfulness  Diagnosis  \\\n",
            "0                   0                          1              0          0   \n",
            "1                   0                          0              1          0   \n",
            "2                   0                          1              0          0   \n",
            "3                   0                          0              0          0   \n",
            "4                   1                          1              0          0   \n",
            "\n",
            "   DoctorInCharge  \n",
            "0       XXXConfid  \n",
            "1       XXXConfid  \n",
            "2       XXXConfid  \n",
            "3       XXXConfid  \n",
            "4       XXXConfid  \n",
            "\n",
            "[5 rows x 35 columns]\n",
            "------------------------------------------------------------------\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2149 entries, 0 to 2148\n",
            "Data columns (total 35 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   PatientID                  2149 non-null   int64  \n",
            " 1   Age                        2149 non-null   int64  \n",
            " 2   Gender                     2149 non-null   int64  \n",
            " 3   Ethnicity                  2149 non-null   int64  \n",
            " 4   EducationLevel             2149 non-null   int64  \n",
            " 5   BMI                        2149 non-null   float64\n",
            " 6   Smoking                    2149 non-null   int64  \n",
            " 7   AlcoholConsumption         2149 non-null   float64\n",
            " 8   PhysicalActivity           2149 non-null   float64\n",
            " 9   DietQuality                2149 non-null   float64\n",
            " 10  SleepQuality               2149 non-null   float64\n",
            " 11  FamilyHistoryAlzheimers    2149 non-null   int64  \n",
            " 12  CardiovascularDisease      2149 non-null   int64  \n",
            " 13  Diabetes                   2149 non-null   int64  \n",
            " 14  Depression                 2149 non-null   int64  \n",
            " 15  HeadInjury                 2149 non-null   int64  \n",
            " 16  Hypertension               2149 non-null   int64  \n",
            " 17  SystolicBP                 2149 non-null   int64  \n",
            " 18  DiastolicBP                2149 non-null   int64  \n",
            " 19  CholesterolTotal           2149 non-null   float64\n",
            " 20  CholesterolLDL             2149 non-null   float64\n",
            " 21  CholesterolHDL             2149 non-null   float64\n",
            " 22  CholesterolTriglycerides   2149 non-null   float64\n",
            " 23  MMSE                       2149 non-null   float64\n",
            " 24  FunctionalAssessment       2149 non-null   float64\n",
            " 25  MemoryComplaints           2149 non-null   int64  \n",
            " 26  BehavioralProblems         2149 non-null   int64  \n",
            " 27  ADL                        2149 non-null   float64\n",
            " 28  Confusion                  2149 non-null   int64  \n",
            " 29  Disorientation             2149 non-null   int64  \n",
            " 30  PersonalityChanges         2149 non-null   int64  \n",
            " 31  DifficultyCompletingTasks  2149 non-null   int64  \n",
            " 32  Forgetfulness              2149 non-null   int64  \n",
            " 33  Diagnosis                  2149 non-null   int64  \n",
            " 34  DoctorInCharge             2149 non-null   object \n",
            "dtypes: float64(12), int64(22), object(1)\n",
            "memory usage: 587.7+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QchFABRiQAN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Organizar los datos\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(data.columns) # Print column names to debug\n",
        "\n",
        "x = data.drop([\"PatientID\", \"Diagnosis\", \"DoctorInCharge\"], axis = 1) #Eliminar la columna del resultado\n",
        "                                                         #Eliminar la columna del doctor y del ID del paciente ya que no es de relevancia para los datos de entrada\n",
        "y = data[\"Diagnosis\"] #Etiqueta para dichos datos\n",
        "\n",
        "#convertir a numpy\n",
        "X = x.values\n",
        "Y = y.values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X[:5])\n",
        "print(\"---------------------------------------------\")\n",
        "print(X_scaled[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cy5wVbPECHR",
        "outputId": "ebd2fa39-bd5c-42f8-df43-48c3e8711973",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PatientID', 'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI',\n",
            "       'Smoking', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
            "       'SleepQuality', 'FamilyHistoryAlzheimers', 'CardiovascularDisease',\n",
            "       'Diabetes', 'Depression', 'HeadInjury', 'Hypertension', 'SystolicBP',\n",
            "       'DiastolicBP', 'CholesterolTotal', 'CholesterolLDL', 'CholesterolHDL',\n",
            "       'CholesterolTriglycerides', 'MMSE', 'FunctionalAssessment',\n",
            "       'MemoryComplaints', 'BehavioralProblems', 'ADL', 'Confusion',\n",
            "       'Disorientation', 'PersonalityChanges', 'DifficultyCompletingTasks',\n",
            "       'Forgetfulness', 'Diagnosis', 'DoctorInCharge'],\n",
            "      dtype='object')\n",
            "[[7.30000000e+01 0.00000000e+00 0.00000000e+00 2.00000000e+00\n",
            "  2.29277492e+01 0.00000000e+00 1.32972177e+01 6.32711247e+00\n",
            "  1.34721431e+00 9.02567867e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.42000000e+02 7.20000000e+01 2.42366840e+02 5.61508970e+01\n",
            "  3.36825635e+01 1.62189143e+02 2.14635324e+01 6.51887697e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.72588346e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
            " [8.90000000e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  2.68276812e+01 0.00000000e+00 4.54252382e+00 7.61988454e+00\n",
            "  5.18767139e-01 7.15129274e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.15000000e+02 6.40000000e+01 2.31162595e+02 1.93407996e+02\n",
            "  7.90284773e+01 2.94630909e+02 2.06132673e+01 7.11869550e+00\n",
            "  0.00000000e+00 0.00000000e+00 2.59242413e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00]\n",
            " [7.30000000e+01 0.00000000e+00 3.00000000e+00 1.00000000e+00\n",
            "  1.77958824e+01 0.00000000e+00 1.95550845e+01 7.84498779e+00\n",
            "  1.82633466e+00 9.67357416e+00 1.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  9.90000000e+01 1.16000000e+02 2.84181858e+02 1.53322762e+02\n",
            "  6.97722919e+01 8.36383241e+01 7.35624862e+00 5.89507735e+00\n",
            "  0.00000000e+00 0.00000000e+00 7.11954774e+00 0.00000000e+00\n",
            "  1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
            " [7.40000000e+01 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
            "  3.38008170e+01 1.00000000e+00 1.22092655e+01 8.42800135e+00\n",
            "  7.43560414e+00 8.39255369e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.18000000e+02 1.15000000e+02 1.59582240e+02 6.53666368e+01\n",
            "  6.84574907e+01 2.77577358e+02 1.39911272e+01 8.96510630e+00\n",
            "  0.00000000e+00 1.00000000e+00 6.48122586e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [8.90000000e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  2.07169738e+01 0.00000000e+00 1.84543561e+01 6.31046069e+00\n",
            "  7.95497509e-01 5.59723768e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  9.40000000e+01 1.17000000e+02 2.37602184e+02 9.28696999e+01\n",
            "  5.68743047e+01 2.91198780e+02 1.35176089e+01 6.04503877e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.46912213e-02 0.00000000e+00\n",
            "  0.00000000e+00 1.00000000e+00 1.00000000e+00 0.00000000e+00]]\n",
            "---------------------------------------------\n",
            "[[-0.21236841 -1.01264391 -0.70040826  0.78883348 -0.65522531 -0.63678394\n",
            "   0.56592307  0.49252491 -1.25359341  1.11991805 -0.58075332 -0.41057262\n",
            "   2.37333437  1.99651669 -0.31945466 -0.418281    0.29815874 -1.01475027\n",
            "   0.40367691 -1.57266058 -1.11442916 -0.64819945  0.77903679  0.49750588\n",
            "  -0.51247653 -0.4312567  -1.10443449 -0.50813061 -0.43353102 -0.42134813\n",
            "   2.30261868 -0.65704809]\n",
            " [ 1.56775727 -1.01264391 -0.70040826 -1.42278185 -0.11475103 -0.63678394\n",
            "  -0.95489457  0.9450928  -1.53844193  0.05683632 -0.58075332 -0.41057262\n",
            "  -0.42134813 -0.50087235 -0.31945466 -0.418281   -0.74257184 -1.46959544\n",
            "   0.14024803  1.59311897  0.84573019  0.65072056  0.68029675  0.70490696\n",
            "  -0.51247653 -0.4312567  -0.81060109 -0.50813061 -0.43353102 -0.42134813\n",
            "  -0.43428815  1.52195861]\n",
            " [-0.21236841 -1.01264391  2.31195467 -0.31697418 -1.36642797 -0.63678394\n",
            "   1.65300553  1.02389594 -1.08885542  1.48738019  1.72190146 -0.41057262\n",
            "  -0.42134813 -0.50087235 -0.31945466 -0.418281   -1.35930107  1.48689818\n",
            "   1.38681173  0.66856925  0.44561479 -1.41858505 -0.85922158  0.28181278\n",
            "  -0.51247653 -0.4312567   0.72449145 -0.50813061  2.30664003 -0.42134813\n",
            "   2.30261868 -0.65704809]\n",
            " [-0.10111056  0.98751396 -0.70040826 -0.31697418  0.85162496  1.57039136\n",
            "   0.37692995  1.22799473  0.83980355  0.76083319 -0.58075332 -0.41057262\n",
            "  -0.42134813 -0.50087235 -0.31945466 -0.418281   -0.62693511  1.43004254\n",
            "  -1.54271524 -1.36010326  0.38878012  0.48346819 -0.08872276  1.34334607\n",
            "  -0.51247653  2.31880456  0.50804427 -0.50813061 -0.43353102 -0.42134813\n",
            "  -0.43428815 -0.65704809]\n",
            " [ 1.56775727 -1.01264391 -0.70040826 -1.42278185 -0.96160687 -0.63678394\n",
            "   1.46179299  0.48669552 -1.44329255 -0.82456571 -0.58075332 -0.41057262\n",
            "  -0.42134813 -0.50087235 -0.31945466 -0.418281   -1.55202896  1.54375383\n",
            "   0.29165258 -0.72575622 -0.1119241   0.61706002 -0.14371176  0.3336654\n",
            "  -0.51247653 -0.4312567  -1.68467896 -0.50813061 -0.43353102  2.37333437\n",
            "   2.30261868 -0.65704809]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "#fijamos un valor de semilla aleatorio fijo para poder probar el modelo después con otros parámetros iniciales pero con ajuste diferente en la red\n",
        "seed = 42 #valor aleatorio predefinido por defecto\n",
        "random.seed(seed)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X_scaled, Y, test_size=0.3, random_state=seed)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=seed)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gaXZMulfPx6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar etiquetas del dataset\n",
        "unique, counts = np.unique(Y, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdHsRfLYhsPf",
        "outputId": "d6841d56-7e52-46b7-dffb-f28028391b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(0): np.int64(1389), np.int64(1): np.int64(760)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Construcción del modelo\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\", use_bias=True),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\", use_bias=True),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\", use_bias=True),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\", use_bias=True),\n",
        "])"
      ],
      "metadata": {
        "id": "BKVNvROUI2tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), #Gradiente descendente para ajustar los pesos de la red\n",
        "    loss = \"binary_crossentropy\", #Entropía cruzada binaria ya que el target Y es 0 o 1\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "-T5r3U4gWP4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wb2PtoumhqrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = model.fit(X_train, Y_train, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t5K5lH3tdTT9",
        "outputId": "bae20484-c276-4284-d46c-328e9231fbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5311 - loss: 0.8170\n",
            "Epoch 2/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5411 - loss: 0.7955\n",
            "Epoch 3/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5520 - loss: 0.7760\n",
            "Epoch 4/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5601 - loss: 0.7579\n",
            "Epoch 5/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5667 - loss: 0.7413\n",
            "Epoch 6/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5769 - loss: 0.7260\n",
            "Epoch 7/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5904 - loss: 0.7119\n",
            "Epoch 8/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6057 - loss: 0.6988\n",
            "Epoch 9/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6112 - loss: 0.6865\n",
            "Epoch 10/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6196 - loss: 0.6751\n",
            "Epoch 11/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6268 - loss: 0.6644\n",
            "Epoch 12/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6341 - loss: 0.6544\n",
            "Epoch 13/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6389 - loss: 0.6449\n",
            "Epoch 14/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6450 - loss: 0.6360\n",
            "Epoch 15/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6576 - loss: 0.6275\n",
            "Epoch 16/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6697 - loss: 0.6194\n",
            "Epoch 17/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6778 - loss: 0.6118\n",
            "Epoch 18/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6844 - loss: 0.6045\n",
            "Epoch 19/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6895 - loss: 0.5975\n",
            "Epoch 20/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6977 - loss: 0.5908\n",
            "Epoch 21/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7059 - loss: 0.5842\n",
            "Epoch 22/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.5779\n",
            "Epoch 23/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.5718\n",
            "Epoch 24/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7160 - loss: 0.5658\n",
            "Epoch 25/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.5599\n",
            "Epoch 26/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.5542\n",
            "Epoch 27/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7425 - loss: 0.5486\n",
            "Epoch 28/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7471 - loss: 0.5432\n",
            "Epoch 29/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7493 - loss: 0.5380\n",
            "Epoch 30/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5328\n",
            "Epoch 31/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7641 - loss: 0.5278\n",
            "Epoch 32/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7665 - loss: 0.5228\n",
            "Epoch 33/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.5180\n",
            "Epoch 34/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7705 - loss: 0.5132\n",
            "Epoch 35/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.5085\n",
            "Epoch 36/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.5039\n",
            "Epoch 37/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7779 - loss: 0.4995\n",
            "Epoch 38/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.4950\n",
            "Epoch 39/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7809 - loss: 0.4906\n",
            "Epoch 40/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7814 - loss: 0.4864\n",
            "Epoch 41/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4822\n",
            "Epoch 42/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7917 - loss: 0.4781\n",
            "Epoch 43/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.4741\n",
            "Epoch 44/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.4702\n",
            "Epoch 45/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7962 - loss: 0.4664\n",
            "Epoch 46/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.4627\n",
            "Epoch 47/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4590\n",
            "Epoch 48/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4555\n",
            "Epoch 49/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4520\n",
            "Epoch 50/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.4486\n",
            "Epoch 51/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8100 - loss: 0.4452\n",
            "Epoch 52/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.4419\n",
            "Epoch 53/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.4387\n",
            "Epoch 54/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8145 - loss: 0.4355\n",
            "Epoch 55/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.4324\n",
            "Epoch 56/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.4293\n",
            "Epoch 57/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8197 - loss: 0.4264\n",
            "Epoch 58/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4235\n",
            "Epoch 59/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.4207\n",
            "Epoch 60/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4179\n",
            "Epoch 61/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4152\n",
            "Epoch 62/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.4126\n",
            "Epoch 63/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8258 - loss: 0.4100\n",
            "Epoch 64/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.4075\n",
            "Epoch 65/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8291 - loss: 0.4050\n",
            "Epoch 66/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8300 - loss: 0.4025\n",
            "Epoch 67/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4001\n",
            "Epoch 68/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.3977\n",
            "Epoch 69/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3954\n",
            "Epoch 70/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.3931\n",
            "Epoch 71/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8350 - loss: 0.3909\n",
            "Epoch 72/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8336 - loss: 0.3887\n",
            "Epoch 73/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.3865\n",
            "Epoch 74/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 0.3845\n",
            "Epoch 75/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8382 - loss: 0.3824\n",
            "Epoch 76/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 0.3804\n",
            "Epoch 77/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 0.3784\n",
            "Epoch 78/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8406 - loss: 0.3765\n",
            "Epoch 79/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.3746\n",
            "Epoch 80/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8452 - loss: 0.3727\n",
            "Epoch 81/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8459 - loss: 0.3708\n",
            "Epoch 82/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8472 - loss: 0.3690\n",
            "Epoch 83/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.3672\n",
            "Epoch 84/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.3654\n",
            "Epoch 85/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.3637\n",
            "Epoch 86/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3620\n",
            "Epoch 87/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.3603\n",
            "Epoch 88/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3587\n",
            "Epoch 89/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.3570\n",
            "Epoch 90/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3554\n",
            "Epoch 91/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8543 - loss: 0.3539\n",
            "Epoch 92/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.3523\n",
            "Epoch 93/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8550 - loss: 0.3508\n",
            "Epoch 94/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3493\n",
            "Epoch 95/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3478\n",
            "Epoch 96/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3463\n",
            "Epoch 97/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3449\n",
            "Epoch 98/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3434\n",
            "Epoch 99/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8618 - loss: 0.3419\n",
            "Epoch 100/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8649 - loss: 0.3405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluacion testeo\n",
        "model.predict(X_test, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4cXDeR7sdKVs",
        "outputId": "04b48528-e588-4f7e-b302-28944d6d472c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42015243],\n",
              "       [0.96274835],\n",
              "       [0.11366344],\n",
              "       [0.06669076],\n",
              "       [0.7270636 ],\n",
              "       [0.02474637],\n",
              "       [0.16603318],\n",
              "       [0.08825628],\n",
              "       [0.1541375 ],\n",
              "       [0.7139866 ],\n",
              "       [0.3087258 ],\n",
              "       [0.13628034],\n",
              "       [0.8976973 ],\n",
              "       [0.17974156],\n",
              "       [0.9873635 ],\n",
              "       [0.9794323 ],\n",
              "       [0.43323234],\n",
              "       [0.5707534 ],\n",
              "       [0.22225541],\n",
              "       [0.68776   ],\n",
              "       [0.07271808],\n",
              "       [0.12214956],\n",
              "       [0.8111799 ],\n",
              "       [0.3949173 ],\n",
              "       [0.02276999],\n",
              "       [0.82210755],\n",
              "       [0.6531424 ],\n",
              "       [0.19577281],\n",
              "       [0.6062115 ],\n",
              "       [0.13583067],\n",
              "       [0.22130314],\n",
              "       [0.8309489 ],\n",
              "       [0.60902953],\n",
              "       [0.144646  ],\n",
              "       [0.22780892],\n",
              "       [0.12487001],\n",
              "       [0.12752685],\n",
              "       [0.4457661 ],\n",
              "       [0.12839328],\n",
              "       [0.03052166],\n",
              "       [0.8450219 ],\n",
              "       [0.9667116 ],\n",
              "       [0.37788066],\n",
              "       [0.07315413],\n",
              "       [0.99861205],\n",
              "       [0.09149183],\n",
              "       [0.88813865],\n",
              "       [0.26826534],\n",
              "       [0.17917627],\n",
              "       [0.0804738 ],\n",
              "       [0.07054745],\n",
              "       [0.12752108],\n",
              "       [0.3841942 ],\n",
              "       [0.22486405],\n",
              "       [0.08494527],\n",
              "       [0.16929972],\n",
              "       [0.77221394],\n",
              "       [0.94653535],\n",
              "       [0.24976411],\n",
              "       [0.06259604],\n",
              "       [0.2645477 ],\n",
              "       [0.19613308],\n",
              "       [0.40183604],\n",
              "       [0.36638263],\n",
              "       [0.99611104],\n",
              "       [0.26109585],\n",
              "       [0.1570448 ],\n",
              "       [0.90996635],\n",
              "       [0.05127926],\n",
              "       [0.19482495],\n",
              "       [0.07502523],\n",
              "       [0.6266954 ],\n",
              "       [0.90924704],\n",
              "       [0.91475815],\n",
              "       [0.05759627],\n",
              "       [0.8380199 ],\n",
              "       [0.11206488],\n",
              "       [0.13364181],\n",
              "       [0.9538936 ],\n",
              "       [0.5187807 ],\n",
              "       [0.11615572],\n",
              "       [0.03351316],\n",
              "       [0.11199986],\n",
              "       [0.02493217],\n",
              "       [0.04141535],\n",
              "       [0.6415017 ],\n",
              "       [0.10915682],\n",
              "       [0.11120825],\n",
              "       [0.0251231 ],\n",
              "       [0.09102319],\n",
              "       [0.15577865],\n",
              "       [0.0448172 ],\n",
              "       [0.39933458],\n",
              "       [0.15576541],\n",
              "       [0.02305203],\n",
              "       [0.52505183],\n",
              "       [0.25330666],\n",
              "       [0.28164887],\n",
              "       [0.6708963 ],\n",
              "       [0.02376505],\n",
              "       [0.86852354],\n",
              "       [0.0885201 ],\n",
              "       [0.28773504],\n",
              "       [0.97839016],\n",
              "       [0.51415664],\n",
              "       [0.893874  ],\n",
              "       [0.1482399 ],\n",
              "       [0.04356783],\n",
              "       [0.40212813],\n",
              "       [0.12210729],\n",
              "       [0.3485971 ],\n",
              "       [0.23902898],\n",
              "       [0.2636433 ],\n",
              "       [0.03771549],\n",
              "       [0.19411123],\n",
              "       [0.07382222],\n",
              "       [0.11018024],\n",
              "       [0.6741347 ],\n",
              "       [0.13189839],\n",
              "       [0.31725338],\n",
              "       [0.08995005],\n",
              "       [0.37823296],\n",
              "       [0.06854046],\n",
              "       [0.13028932],\n",
              "       [0.2745485 ],\n",
              "       [0.13761339],\n",
              "       [0.05948516],\n",
              "       [0.05019303],\n",
              "       [0.34897485],\n",
              "       [0.08672706],\n",
              "       [0.0573868 ],\n",
              "       [0.5414643 ],\n",
              "       [0.03949163],\n",
              "       [0.28648695],\n",
              "       [0.09862874],\n",
              "       [0.3662679 ],\n",
              "       [0.8337222 ],\n",
              "       [0.96465737],\n",
              "       [0.4880109 ],\n",
              "       [0.0446002 ],\n",
              "       [0.61098224],\n",
              "       [0.341775  ],\n",
              "       [0.86122257],\n",
              "       [0.80320054],\n",
              "       [0.14780131],\n",
              "       [0.15123194],\n",
              "       [0.50658053],\n",
              "       [0.0139955 ],\n",
              "       [0.23539174],\n",
              "       [0.15735598],\n",
              "       [0.24958421],\n",
              "       [0.4922944 ],\n",
              "       [0.11307378],\n",
              "       [0.09330557],\n",
              "       [0.8709418 ],\n",
              "       [0.18873192],\n",
              "       [0.13564642],\n",
              "       [0.99462765],\n",
              "       [0.12226457],\n",
              "       [0.8136058 ],\n",
              "       [0.39467   ],\n",
              "       [0.09071723],\n",
              "       [0.2622408 ],\n",
              "       [0.9823121 ],\n",
              "       [0.93914276],\n",
              "       [0.1246253 ],\n",
              "       [0.10344741],\n",
              "       [0.04571867],\n",
              "       [0.0542964 ],\n",
              "       [0.65469116],\n",
              "       [0.60900444],\n",
              "       [0.3748846 ],\n",
              "       [0.835199  ],\n",
              "       [0.5610678 ],\n",
              "       [0.04966062],\n",
              "       [0.0325493 ],\n",
              "       [0.12571165],\n",
              "       [0.14641954],\n",
              "       [0.22176005],\n",
              "       [0.13547198],\n",
              "       [0.99723554],\n",
              "       [0.19069612],\n",
              "       [0.2820921 ],\n",
              "       [0.18290628],\n",
              "       [0.19463104],\n",
              "       [0.5137999 ],\n",
              "       [0.12976222],\n",
              "       [0.04938059],\n",
              "       [0.06486678],\n",
              "       [0.20339057],\n",
              "       [0.06222913],\n",
              "       [0.6066365 ],\n",
              "       [0.06782892],\n",
              "       [0.70115197],\n",
              "       [0.21517527],\n",
              "       [0.4315624 ],\n",
              "       [0.8466611 ],\n",
              "       [0.03688203],\n",
              "       [0.9993375 ],\n",
              "       [0.42266777],\n",
              "       [0.6455968 ],\n",
              "       [0.06602146],\n",
              "       [0.13905522],\n",
              "       [0.9135829 ],\n",
              "       [0.629734  ],\n",
              "       [0.31219938],\n",
              "       [0.45594248],\n",
              "       [0.06177619],\n",
              "       [0.73122114],\n",
              "       [0.17890804],\n",
              "       [0.20127897],\n",
              "       [0.19495676],\n",
              "       [0.10274038],\n",
              "       [0.20316227],\n",
              "       [0.28003898],\n",
              "       [0.4684426 ],\n",
              "       [0.7919882 ],\n",
              "       [0.06929685],\n",
              "       [0.40464064],\n",
              "       [0.92425597],\n",
              "       [0.05967695],\n",
              "       [0.34843138],\n",
              "       [0.09538593],\n",
              "       [0.443699  ],\n",
              "       [0.07790214],\n",
              "       [0.04174723],\n",
              "       [0.12983827],\n",
              "       [0.28391024],\n",
              "       [0.10970702],\n",
              "       [0.04067862],\n",
              "       [0.9957621 ],\n",
              "       [0.02051113],\n",
              "       [0.12475009],\n",
              "       [0.92835665],\n",
              "       [0.09320178],\n",
              "       [0.10724524],\n",
              "       [0.04760537],\n",
              "       [0.08367309],\n",
              "       [0.9740575 ],\n",
              "       [0.10386278],\n",
              "       [0.94821054],\n",
              "       [0.80417675],\n",
              "       [0.15735252],\n",
              "       [0.2899011 ],\n",
              "       [0.22541684],\n",
              "       [0.12233964],\n",
              "       [0.52066886],\n",
              "       [0.26752168],\n",
              "       [0.9863837 ],\n",
              "       [0.48592007],\n",
              "       [0.60670483],\n",
              "       [0.1963078 ],\n",
              "       [0.14654553],\n",
              "       [0.04005082],\n",
              "       [0.12777466],\n",
              "       [0.28120995],\n",
              "       [0.5403533 ],\n",
              "       [0.897757  ],\n",
              "       [0.11736131],\n",
              "       [0.16183412],\n",
              "       [0.09137902],\n",
              "       [0.62707853],\n",
              "       [0.02863008],\n",
              "       [0.01696865],\n",
              "       [0.13506806],\n",
              "       [0.06088686],\n",
              "       [0.38014117],\n",
              "       [0.16517562],\n",
              "       [0.12016886],\n",
              "       [0.14596632],\n",
              "       [0.27220216],\n",
              "       [0.09578092],\n",
              "       [0.25679502],\n",
              "       [0.152069  ],\n",
              "       [0.9611232 ],\n",
              "       [0.5854699 ],\n",
              "       [0.36398238],\n",
              "       [0.4611718 ],\n",
              "       [0.43027723],\n",
              "       [0.9869245 ],\n",
              "       [0.12636201],\n",
              "       [0.16876212],\n",
              "       [0.6654808 ],\n",
              "       [0.22442704],\n",
              "       [0.06214704],\n",
              "       [0.43228516],\n",
              "       [0.5630084 ],\n",
              "       [0.22766013],\n",
              "       [0.0641987 ],\n",
              "       [0.11610413],\n",
              "       [0.2120361 ],\n",
              "       [0.9710851 ],\n",
              "       [0.10764017],\n",
              "       [0.04724736],\n",
              "       [0.8458385 ],\n",
              "       [0.24730869],\n",
              "       [0.7865364 ],\n",
              "       [0.22696622],\n",
              "       [0.06699193],\n",
              "       [0.07261365],\n",
              "       [0.05424679],\n",
              "       [0.13989168],\n",
              "       [0.9949409 ],\n",
              "       [0.7125602 ],\n",
              "       [0.04593011],\n",
              "       [0.05382621],\n",
              "       [0.07294852],\n",
              "       [0.7737984 ],\n",
              "       [0.08453897],\n",
              "       [0.9886668 ],\n",
              "       [0.10983538],\n",
              "       [0.7155404 ],\n",
              "       [0.62590176],\n",
              "       [0.5758018 ],\n",
              "       [0.13245499],\n",
              "       [0.1443113 ],\n",
              "       [0.02899145],\n",
              "       [0.9173159 ],\n",
              "       [0.18378122],\n",
              "       [0.04354154],\n",
              "       [0.20235048],\n",
              "       [0.14881319],\n",
              "       [0.07749549]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluación modelo\n",
        "model.fit(\n",
        "  X_train, Y_train, shuffle=True, epochs=100, batch_size=32, validation_data=(X_val, Y_val)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h28niBl8eu5H",
        "outputId": "bfc49906-2c6f-4f5c-ff73-a289ff3055d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8666 - loss: 0.3390 - val_accuracy: 0.7547 - val_loss: 0.5230\n",
            "Epoch 2/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8694 - loss: 0.3376 - val_accuracy: 0.7547 - val_loss: 0.5230\n",
            "Epoch 3/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8697 - loss: 0.3362 - val_accuracy: 0.7547 - val_loss: 0.5230\n",
            "Epoch 4/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8697 - loss: 0.3348 - val_accuracy: 0.7547 - val_loss: 0.5230\n",
            "Epoch 5/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.3334 - val_accuracy: 0.7547 - val_loss: 0.5230\n",
            "Epoch 6/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.3320 - val_accuracy: 0.7609 - val_loss: 0.5230\n",
            "Epoch 7/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.3306 - val_accuracy: 0.7609 - val_loss: 0.5230\n",
            "Epoch 8/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.3293 - val_accuracy: 0.7609 - val_loss: 0.5231\n",
            "Epoch 9/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.3279 - val_accuracy: 0.7671 - val_loss: 0.5231\n",
            "Epoch 10/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.3266 - val_accuracy: 0.7671 - val_loss: 0.5232\n",
            "Epoch 11/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 0.3253 - val_accuracy: 0.7702 - val_loss: 0.5232\n",
            "Epoch 12/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8764 - loss: 0.3240 - val_accuracy: 0.7702 - val_loss: 0.5233\n",
            "Epoch 13/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3227 - val_accuracy: 0.7702 - val_loss: 0.5235\n",
            "Epoch 14/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3214 - val_accuracy: 0.7702 - val_loss: 0.5237\n",
            "Epoch 15/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8767 - loss: 0.3201 - val_accuracy: 0.7702 - val_loss: 0.5238\n",
            "Epoch 16/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8780 - loss: 0.3188 - val_accuracy: 0.7702 - val_loss: 0.5240\n",
            "Epoch 17/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8783 - loss: 0.3176 - val_accuracy: 0.7702 - val_loss: 0.5241\n",
            "Epoch 18/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8791 - loss: 0.3163 - val_accuracy: 0.7702 - val_loss: 0.5243\n",
            "Epoch 19/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8795 - loss: 0.3150 - val_accuracy: 0.7702 - val_loss: 0.5245\n",
            "Epoch 20/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.3138 - val_accuracy: 0.7702 - val_loss: 0.5246\n",
            "Epoch 21/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.3126 - val_accuracy: 0.7702 - val_loss: 0.5248\n",
            "Epoch 22/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.3114 - val_accuracy: 0.7702 - val_loss: 0.5250\n",
            "Epoch 23/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.3101 - val_accuracy: 0.7702 - val_loss: 0.5252\n",
            "Epoch 24/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.3089 - val_accuracy: 0.7702 - val_loss: 0.5255\n",
            "Epoch 25/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.3078 - val_accuracy: 0.7702 - val_loss: 0.5257\n",
            "Epoch 26/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.3066 - val_accuracy: 0.7702 - val_loss: 0.5259\n",
            "Epoch 27/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.3054 - val_accuracy: 0.7702 - val_loss: 0.5262\n",
            "Epoch 28/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.3042 - val_accuracy: 0.7702 - val_loss: 0.5264\n",
            "Epoch 29/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3031 - val_accuracy: 0.7733 - val_loss: 0.5267\n",
            "Epoch 30/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8859 - loss: 0.3019 - val_accuracy: 0.7733 - val_loss: 0.5270\n",
            "Epoch 31/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8859 - loss: 0.3008 - val_accuracy: 0.7733 - val_loss: 0.5273\n",
            "Epoch 32/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8857 - loss: 0.2996 - val_accuracy: 0.7733 - val_loss: 0.5276\n",
            "Epoch 33/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8884 - loss: 0.2985 - val_accuracy: 0.7733 - val_loss: 0.5279\n",
            "Epoch 34/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.2974 - val_accuracy: 0.7733 - val_loss: 0.5283\n",
            "Epoch 35/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2962 - val_accuracy: 0.7733 - val_loss: 0.5285\n",
            "Epoch 36/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.2951 - val_accuracy: 0.7764 - val_loss: 0.5289\n",
            "Epoch 37/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.2939 - val_accuracy: 0.7764 - val_loss: 0.5292\n",
            "Epoch 38/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.2928 - val_accuracy: 0.7733 - val_loss: 0.5295\n",
            "Epoch 39/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8897 - loss: 0.2917 - val_accuracy: 0.7764 - val_loss: 0.5297\n",
            "Epoch 40/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8903 - loss: 0.2906 - val_accuracy: 0.7764 - val_loss: 0.5300\n",
            "Epoch 41/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.2895 - val_accuracy: 0.7764 - val_loss: 0.5304\n",
            "Epoch 42/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.2884 - val_accuracy: 0.7764 - val_loss: 0.5307\n",
            "Epoch 43/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.2873 - val_accuracy: 0.7733 - val_loss: 0.5310\n",
            "Epoch 44/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.2862 - val_accuracy: 0.7733 - val_loss: 0.5313\n",
            "Epoch 45/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.2850 - val_accuracy: 0.7733 - val_loss: 0.5317\n",
            "Epoch 46/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8924 - loss: 0.2839 - val_accuracy: 0.7733 - val_loss: 0.5321\n",
            "Epoch 47/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.2828 - val_accuracy: 0.7702 - val_loss: 0.5324\n",
            "Epoch 48/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.2817 - val_accuracy: 0.7702 - val_loss: 0.5327\n",
            "Epoch 49/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 0.2806 - val_accuracy: 0.7702 - val_loss: 0.5331\n",
            "Epoch 50/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 0.2796 - val_accuracy: 0.7702 - val_loss: 0.5334\n",
            "Epoch 51/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.2785 - val_accuracy: 0.7671 - val_loss: 0.5337\n",
            "Epoch 52/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8944 - loss: 0.2774 - val_accuracy: 0.7671 - val_loss: 0.5340\n",
            "Epoch 53/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8962 - loss: 0.2763 - val_accuracy: 0.7671 - val_loss: 0.5344\n",
            "Epoch 54/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8976 - loss: 0.2752 - val_accuracy: 0.7671 - val_loss: 0.5347\n",
            "Epoch 55/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8974 - loss: 0.2742 - val_accuracy: 0.7671 - val_loss: 0.5350\n",
            "Epoch 56/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8981 - loss: 0.2731 - val_accuracy: 0.7671 - val_loss: 0.5354\n",
            "Epoch 57/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9003 - loss: 0.2721 - val_accuracy: 0.7671 - val_loss: 0.5357\n",
            "Epoch 58/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9025 - loss: 0.2710 - val_accuracy: 0.7671 - val_loss: 0.5361\n",
            "Epoch 59/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.2700 - val_accuracy: 0.7671 - val_loss: 0.5365\n",
            "Epoch 60/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.2690 - val_accuracy: 0.7671 - val_loss: 0.5368\n",
            "Epoch 61/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9032 - loss: 0.2679 - val_accuracy: 0.7671 - val_loss: 0.5372\n",
            "Epoch 62/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.2669 - val_accuracy: 0.7671 - val_loss: 0.5376\n",
            "Epoch 63/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.2659 - val_accuracy: 0.7671 - val_loss: 0.5380\n",
            "Epoch 64/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2649 - val_accuracy: 0.7671 - val_loss: 0.5384\n",
            "Epoch 65/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9050 - loss: 0.2639 - val_accuracy: 0.7671 - val_loss: 0.5388\n",
            "Epoch 66/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9050 - loss: 0.2628 - val_accuracy: 0.7671 - val_loss: 0.5391\n",
            "Epoch 67/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2618 - val_accuracy: 0.7671 - val_loss: 0.5396\n",
            "Epoch 68/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2608 - val_accuracy: 0.7671 - val_loss: 0.5400\n",
            "Epoch 69/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2599 - val_accuracy: 0.7671 - val_loss: 0.5403\n",
            "Epoch 70/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2589 - val_accuracy: 0.7671 - val_loss: 0.5406\n",
            "Epoch 71/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9060 - loss: 0.2579 - val_accuracy: 0.7671 - val_loss: 0.5410\n",
            "Epoch 72/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.2569 - val_accuracy: 0.7671 - val_loss: 0.5413\n",
            "Epoch 73/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.2560 - val_accuracy: 0.7702 - val_loss: 0.5417\n",
            "Epoch 74/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2550 - val_accuracy: 0.7702 - val_loss: 0.5420\n",
            "Epoch 75/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.2540 - val_accuracy: 0.7702 - val_loss: 0.5423\n",
            "Epoch 76/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9099 - loss: 0.2531 - val_accuracy: 0.7702 - val_loss: 0.5428\n",
            "Epoch 77/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2521 - val_accuracy: 0.7702 - val_loss: 0.5431\n",
            "Epoch 78/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9106 - loss: 0.2511 - val_accuracy: 0.7702 - val_loss: 0.5435\n",
            "Epoch 79/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2502 - val_accuracy: 0.7702 - val_loss: 0.5438\n",
            "Epoch 80/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2493 - val_accuracy: 0.7733 - val_loss: 0.5442\n",
            "Epoch 81/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2483 - val_accuracy: 0.7733 - val_loss: 0.5447\n",
            "Epoch 82/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9117 - loss: 0.2474 - val_accuracy: 0.7733 - val_loss: 0.5451\n",
            "Epoch 83/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.2464 - val_accuracy: 0.7733 - val_loss: 0.5456\n",
            "Epoch 84/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2455 - val_accuracy: 0.7733 - val_loss: 0.5460\n",
            "Epoch 85/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9146 - loss: 0.2445 - val_accuracy: 0.7733 - val_loss: 0.5464\n",
            "Epoch 86/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9146 - loss: 0.2436 - val_accuracy: 0.7733 - val_loss: 0.5468\n",
            "Epoch 87/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9170 - loss: 0.2427 - val_accuracy: 0.7733 - val_loss: 0.5473\n",
            "Epoch 88/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9170 - loss: 0.2418 - val_accuracy: 0.7733 - val_loss: 0.5478\n",
            "Epoch 89/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9205 - loss: 0.2408 - val_accuracy: 0.7764 - val_loss: 0.5482\n",
            "Epoch 90/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9205 - loss: 0.2399 - val_accuracy: 0.7764 - val_loss: 0.5487\n",
            "Epoch 91/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2390 - val_accuracy: 0.7764 - val_loss: 0.5491\n",
            "Epoch 92/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2380 - val_accuracy: 0.7764 - val_loss: 0.5496\n",
            "Epoch 93/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.2371 - val_accuracy: 0.7764 - val_loss: 0.5501\n",
            "Epoch 94/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.2362 - val_accuracy: 0.7764 - val_loss: 0.5505\n",
            "Epoch 95/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.2353 - val_accuracy: 0.7764 - val_loss: 0.5510\n",
            "Epoch 96/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2344 - val_accuracy: 0.7764 - val_loss: 0.5514\n",
            "Epoch 97/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2335 - val_accuracy: 0.7733 - val_loss: 0.5519\n",
            "Epoch 98/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9224 - loss: 0.2326 - val_accuracy: 0.7733 - val_loss: 0.5524\n",
            "Epoch 99/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.2316 - val_accuracy: 0.7733 - val_loss: 0.5529\n",
            "Epoch 100/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.2307 - val_accuracy: 0.7733 - val_loss: 0.5533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79c51b4b91c0>"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred_proba = model.predict(X_test)\n",
        "\n",
        "# convertir a 0/1 según un umbral (normalmente 0.5)\n",
        "y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "\n",
        "cm = confusion_matrix(Y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "qDkthu6nj5FW",
        "outputId": "1078b5ff-18f8-4e2f-a21b-092df332cf57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(Y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3v6C5zcD1gN",
        "outputId": "86ac9a8b-32b6-49ee-f1f4-ac4e2c6e0471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       221\n",
            "           1       0.70      0.63      0.66       102\n",
            "\n",
            "    accuracy                           0.80       323\n",
            "   macro avg       0.77      0.75      0.76       323\n",
            "weighted avg       0.79      0.80      0.80       323\n",
            "\n"
          ]
        }
      ]
    }
  ]
}